
âžœ  bandit git:(master) p start.py
Episode 0, elapsed time: 0 (avg 0.1098), current_reward: 0.0500 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 20, elapsed time: 2 (avg 0.0904), current_reward: 0.4825 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 40, elapsed time: 4 (avg 0.0889), current_reward: 0.4300 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 60, elapsed time: 5 (avg 0.0888), current_reward: 0.5715 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 80, elapsed time: 7 (avg 0.0885), current_reward: 0.4975 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 100, elapsed time: 9 (avg 0.0925), current_reward: 0.4270 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 120, elapsed time: 11 (avg 0.0918), current_reward: 0.4385 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 140, elapsed time: 13 (avg 0.1067), current_reward: 0.5430 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 160, elapsed time: 15 (avg 0.1030), current_reward: 0.4070 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 180, elapsed time: 17 (avg 0.0954), current_reward: 0.3705 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 200, elapsed time: 19 (avg 0.1003), current_reward: 0.5420 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 220, elapsed time: 21 (avg 0.0962), current_reward: 0.5365 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 240, elapsed time: 23 (avg 0.0887), current_reward: 0.4900 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 260, elapsed time: 24 (avg 0.0875), current_reward: 0.4970 Action mean: [0.5] Action std: [0.5]
Episode 280, elapsed time: 26 (avg 0.0934), current_reward: 0.4590 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 300, elapsed time: 28 (avg 0.1040), current_reward: 0.4305 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 320, elapsed time: 30 (avg 0.0956), current_reward: 0.4895 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 340, elapsed time: 32 (avg 0.0959), current_reward: 0.5010 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 360, elapsed time: 34 (avg 0.0875), current_reward: 0.5595 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 380, elapsed time: 36 (avg 0.0919), current_reward: 0.4325 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 400, elapsed time: 38 (avg 0.0902), current_reward: 0.4225 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 420, elapsed time: 40 (avg 0.1007), current_reward: 0.4685 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 440, elapsed time: 42 (avg 0.1020), current_reward: 0.4940 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 460, elapsed time: 44 (avg 0.0986), current_reward: 0.4665 Action mean: [0.55] Action std: [0.49749371855331]
Episode 480, elapsed time: 46 (avg 0.1080), current_reward: 0.4195 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 500, elapsed time: 48 (avg 0.0936), current_reward: 0.4805 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 520, elapsed time: 50 (avg 0.0940), current_reward: 0.4480 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 540, elapsed time: 52 (avg 0.0971), current_reward: 0.4940 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 560, elapsed time: 53 (avg 0.0888), current_reward: 0.5575 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 580, elapsed time: 55 (avg 0.0935), current_reward: 0.5185 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 600, elapsed time: 57 (avg 0.0866), current_reward: 0.5040 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 620, elapsed time: 59 (avg 0.0858), current_reward: 0.4455 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 640, elapsed time: 60 (avg 0.0860), current_reward: 0.5665 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 660, elapsed time: 62 (avg 0.0860), current_reward: 0.5685 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 680, elapsed time: 64 (avg 0.0864), current_reward: 0.4950 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 700, elapsed time: 66 (avg 0.0860), current_reward: 0.5470 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 720, elapsed time: 67 (avg 0.0858), current_reward: 0.4895 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 740, elapsed time: 69 (avg 0.0940), current_reward: 0.4035 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 760, elapsed time: 71 (avg 0.0905), current_reward: 0.5225 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 780, elapsed time: 73 (avg 0.0889), current_reward: 0.4490 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 800, elapsed time: 75 (avg 0.0951), current_reward: 0.4465 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 820, elapsed time: 76 (avg 0.0886), current_reward: 0.4785 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 840, elapsed time: 78 (avg 0.0883), current_reward: 0.5305 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 860, elapsed time: 80 (avg 0.0880), current_reward: 0.5355 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 880, elapsed time: 82 (avg 0.0879), current_reward: 0.4860 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 900, elapsed time: 83 (avg 0.0877), current_reward: 0.4455 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 920, elapsed time: 85 (avg 0.0878), current_reward: 0.4680 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 940, elapsed time: 87 (avg 0.0877), current_reward: 0.4880 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 960, elapsed time: 89 (avg 0.0877), current_reward: 0.4440 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 980, elapsed time: 90 (avg 0.0888), current_reward: 0.5230 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 1000, elapsed time: 92 (avg 0.1011), current_reward: 0.5285 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 1020, elapsed time: 94 (avg 0.0901), current_reward: 0.5360 Action mean: [0.5] Action std: [0.5]
Episode 1040, elapsed time: 96 (avg 0.0933), current_reward: 0.4785 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 1060, elapsed time: 98 (avg 0.0900), current_reward: 0.5280 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 1080, elapsed time: 100 (avg 0.0898), current_reward: 0.5680 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1100, elapsed time: 102 (avg 0.0898), current_reward: 0.4420 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 1120, elapsed time: 103 (avg 0.0892), current_reward: 0.5255 Action mean: [0.5] Action std: [0.5]
Episode 1140, elapsed time: 105 (avg 0.0881), current_reward: 0.5065 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 1160, elapsed time: 107 (avg 0.0878), current_reward: 0.3840 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 1180, elapsed time: 109 (avg 0.0877), current_reward: 0.5050 Action mean: [0.5] Action std: [0.5]
Episode 1200, elapsed time: 110 (avg 0.0878), current_reward: 0.4955 Action mean: [0.5] Action std: [0.5]
Episode 1220, elapsed time: 112 (avg 0.0879), current_reward: 0.4990 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 1240, elapsed time: 114 (avg 0.0921), current_reward: 0.5275 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 1260, elapsed time: 116 (avg 0.1006), current_reward: 0.5240 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 1280, elapsed time: 118 (avg 0.0967), current_reward: 0.4775 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 1300, elapsed time: 120 (avg 0.1014), current_reward: 0.4535 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 1320, elapsed time: 122 (avg 0.0963), current_reward: 0.4705 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 1340, elapsed time: 124 (avg 0.0964), current_reward: 0.5290 Action mean: [0.36] Action std: [0.48]
Episode 1360, elapsed time: 126 (avg 0.0946), current_reward: 0.5180 Action mean: [0.5] Action std: [0.5]
Episode 1380, elapsed time: 128 (avg 0.1049), current_reward: 0.4890 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 1400, elapsed time: 130 (avg 0.0970), current_reward: 0.4255 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 1420, elapsed time: 132 (avg 0.0898), current_reward: 0.4945 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 1440, elapsed time: 133 (avg 0.0898), current_reward: 0.4830 Action mean: [0.58] Action std: [0.49355850717012273]
Episode 1460, elapsed time: 135 (avg 0.0898), current_reward: 0.4765 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 1480, elapsed time: 137 (avg 0.0897), current_reward: 0.4865 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 1500, elapsed time: 139 (avg 0.0895), current_reward: 0.5135 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 1520, elapsed time: 140 (avg 0.0897), current_reward: 0.5185 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 1540, elapsed time: 142 (avg 0.0896), current_reward: 0.5140 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1560, elapsed time: 144 (avg 0.0938), current_reward: 0.3865 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 1580, elapsed time: 146 (avg 0.0977), current_reward: 0.4700 Action mean: [0.5] Action std: [0.5]
Episode 1600, elapsed time: 148 (avg 0.0892), current_reward: 0.4555 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 1620, elapsed time: 150 (avg 0.0980), current_reward: 0.5365 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1640, elapsed time: 152 (avg 0.0995), current_reward: 0.5525 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 1660, elapsed time: 154 (avg 0.0898), current_reward: 0.4345 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1680, elapsed time: 156 (avg 0.0963), current_reward: 0.5455 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 1700, elapsed time: 157 (avg 0.0970), current_reward: 0.4410 Action mean: [0.5] Action std: [0.5]
Episode 1720, elapsed time: 159 (avg 0.0892), current_reward: 0.5265 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1740, elapsed time: 161 (avg 0.0960), current_reward: 0.5105 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 1760, elapsed time: 163 (avg 0.0960), current_reward: 0.5940 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 1780, elapsed time: 165 (avg 0.0941), current_reward: 0.4930 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 1800, elapsed time: 167 (avg 0.0960), current_reward: 0.5585 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 1820, elapsed time: 169 (avg 0.0956), current_reward: 0.4850 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 1840, elapsed time: 171 (avg 0.0877), current_reward: 0.5235 Action mean: [0.34] Action std: [0.4737087712930804]
Episode 1860, elapsed time: 172 (avg 0.0931), current_reward: 0.4450 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 1880, elapsed time: 174 (avg 0.0986), current_reward: 0.4670 Action mean: [0.45] Action std: [0.49749371855331]
Episode 1900, elapsed time: 176 (avg 0.0930), current_reward: 0.5200 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 1920, elapsed time: 178 (avg 0.0957), current_reward: 0.5150 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 1940, elapsed time: 180 (avg 0.0943), current_reward: 0.4425 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 1960, elapsed time: 182 (avg 0.0916), current_reward: 0.4050 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 1980, elapsed time: 184 (avg 0.0880), current_reward: 0.5810 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 2000, elapsed time: 185 (avg 0.0867), current_reward: 0.5215 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 2020, elapsed time: 187 (avg 0.0861), current_reward: 0.4840 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 2040, elapsed time: 189 (avg 0.0867), current_reward: 0.5665 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 2060, elapsed time: 191 (avg 0.0900), current_reward: 0.5250 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 2080, elapsed time: 192 (avg 0.0858), current_reward: 0.4810 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 2100, elapsed time: 194 (avg 0.0921), current_reward: 0.4845 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 2120, elapsed time: 196 (avg 0.0929), current_reward: 0.5185 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 2140, elapsed time: 198 (avg 0.0895), current_reward: 0.4265 Action mean: [0.5] Action std: [0.5]
Episode 2160, elapsed time: 200 (avg 0.0899), current_reward: 0.4760 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 2180, elapsed time: 202 (avg 0.0923), current_reward: 0.5175 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 2200, elapsed time: 203 (avg 0.0936), current_reward: 0.4590 Action mean: [0.36] Action std: [0.48]
Episode 2220, elapsed time: 205 (avg 0.1007), current_reward: 0.5470 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 2240, elapsed time: 207 (avg 0.0984), current_reward: 0.5675 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 2260, elapsed time: 209 (avg 0.1013), current_reward: 0.5135 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 2280, elapsed time: 211 (avg 0.0929), current_reward: 0.4690 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 2300, elapsed time: 213 (avg 0.1014), current_reward: 0.4900 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 2320, elapsed time: 215 (avg 0.0953), current_reward: 0.4570 Action mean: [0.39] Action std: [0.487749935930288]
Episode 2340, elapsed time: 217 (avg 0.0883), current_reward: 0.5545 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 2360, elapsed time: 219 (avg 0.0877), current_reward: 0.4875 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 2380, elapsed time: 220 (avg 0.0875), current_reward: 0.4930 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 2400, elapsed time: 222 (avg 0.0870), current_reward: 0.4900 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 2420, elapsed time: 224 (avg 0.0879), current_reward: 0.5200 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 2440, elapsed time: 226 (avg 0.0870), current_reward: 0.5585 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 2460, elapsed time: 227 (avg 0.0864), current_reward: 0.6470 Action mean: [0.56] Action std: [0.4963869458396343]
Episode 2480, elapsed time: 229 (avg 0.0867), current_reward: 0.5325 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 2500, elapsed time: 231 (avg 0.0869), current_reward: 0.4500 Action mean: [0.36] Action std: [0.48]
Episode 2520, elapsed time: 233 (avg 0.0869), current_reward: 0.4445 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 2540, elapsed time: 234 (avg 0.0905), current_reward: 0.4855 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 2560, elapsed time: 236 (avg 0.0865), current_reward: 0.5130 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 2580, elapsed time: 238 (avg 0.0868), current_reward: 0.5005 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 2600, elapsed time: 240 (avg 0.0867), current_reward: 0.4970 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 2620, elapsed time: 241 (avg 0.0868), current_reward: 0.4785 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 2640, elapsed time: 243 (avg 0.0864), current_reward: 0.5690 Action mean: [0.35] Action std: [0.47696960070847283]
Episode 2660, elapsed time: 245 (avg 0.0870), current_reward: 0.4645 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 2680, elapsed time: 247 (avg 0.0899), current_reward: 0.5555 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 2700, elapsed time: 249 (avg 0.0981), current_reward: 0.5685 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 2720, elapsed time: 252 (avg 0.1462), current_reward: 0.3950 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 2740, elapsed time: 254 (avg 0.1097), current_reward: 0.5225 Action mean: [0.37] Action std: [0.48280430818293246]
Episode 2760, elapsed time: 256 (avg 0.0946), current_reward: 0.3895 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 2780, elapsed time: 257 (avg 0.0927), current_reward: 0.4945 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 2800, elapsed time: 259 (avg 0.0919), current_reward: 0.4400 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 2820, elapsed time: 261 (avg 0.0938), current_reward: 0.4690 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 2840, elapsed time: 263 (avg 0.0968), current_reward: 0.4620 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 2860, elapsed time: 265 (avg 0.0953), current_reward: 0.4725 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 2880, elapsed time: 267 (avg 0.0929), current_reward: 0.5220 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 2900, elapsed time: 269 (avg 0.0942), current_reward: 0.4285 Action mean: [0.5] Action std: [0.5]
Episode 2920, elapsed time: 271 (avg 0.0941), current_reward: 0.4260 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 2940, elapsed time: 273 (avg 0.1132), current_reward: 0.4355 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 2960, elapsed time: 275 (avg 0.1042), current_reward: 0.5280 Action mean: [0.57] Action std: [0.49507575177946245]
Episode 2980, elapsed time: 277 (avg 0.0908), current_reward: 0.4895 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3000, elapsed time: 279 (avg 0.0942), current_reward: 0.4860 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 3020, elapsed time: 281 (avg 0.0921), current_reward: 0.4905 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3040, elapsed time: 282 (avg 0.0914), current_reward: 0.5490 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 3060, elapsed time: 284 (avg 0.0930), current_reward: 0.4915 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3080, elapsed time: 286 (avg 0.0979), current_reward: 0.4940 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 3100, elapsed time: 288 (avg 0.0900), current_reward: 0.5030 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 3120, elapsed time: 290 (avg 0.0888), current_reward: 0.5775 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 3140, elapsed time: 292 (avg 0.0876), current_reward: 0.4985 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 3160, elapsed time: 293 (avg 0.0974), current_reward: 0.5015 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 3180, elapsed time: 295 (avg 0.0950), current_reward: 0.5880 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 3200, elapsed time: 297 (avg 0.0985), current_reward: 0.5415 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 3220, elapsed time: 299 (avg 0.0966), current_reward: 0.5365 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 3240, elapsed time: 301 (avg 0.0964), current_reward: 0.5000 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 3260, elapsed time: 303 (avg 0.0914), current_reward: 0.4910 Action mean: [0.5] Action std: [0.5]
Episode 3280, elapsed time: 305 (avg 0.0880), current_reward: 0.4360 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 3300, elapsed time: 307 (avg 0.0883), current_reward: 0.5090 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3320, elapsed time: 308 (avg 0.0924), current_reward: 0.3705 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 3340, elapsed time: 310 (avg 0.0926), current_reward: 0.5275 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 3360, elapsed time: 312 (avg 0.0938), current_reward: 0.4845 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3380, elapsed time: 314 (avg 0.0930), current_reward: 0.5705 Action mean: [0.5] Action std: [0.5]
Episode 3400, elapsed time: 316 (avg 0.0937), current_reward: 0.5885 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 3420, elapsed time: 318 (avg 0.1139), current_reward: 0.4640 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 3440, elapsed time: 320 (avg 0.0926), current_reward: 0.4890 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 3460, elapsed time: 322 (avg 0.0940), current_reward: 0.5210 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3480, elapsed time: 324 (avg 0.0935), current_reward: 0.4680 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 3500, elapsed time: 326 (avg 0.0924), current_reward: 0.4570 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 3520, elapsed time: 327 (avg 0.0888), current_reward: 0.4915 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 3540, elapsed time: 329 (avg 0.0990), current_reward: 0.5335 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 3560, elapsed time: 331 (avg 0.1033), current_reward: 0.4170 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 3580, elapsed time: 333 (avg 0.0989), current_reward: 0.4085 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 3600, elapsed time: 335 (avg 0.0950), current_reward: 0.4850 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 3620, elapsed time: 337 (avg 0.0898), current_reward: 0.5415 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 3640, elapsed time: 339 (avg 0.0906), current_reward: 0.4205 Action mean: [0.5] Action std: [0.5]
Episode 3660, elapsed time: 341 (avg 0.0949), current_reward: 0.4810 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 3680, elapsed time: 343 (avg 0.0899), current_reward: 0.4385 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 3700, elapsed time: 344 (avg 0.0886), current_reward: 0.4970 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 3720, elapsed time: 346 (avg 0.0911), current_reward: 0.5565 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 3740, elapsed time: 348 (avg 0.0915), current_reward: 0.5000 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3760, elapsed time: 350 (avg 0.0884), current_reward: 0.4875 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 3780, elapsed time: 352 (avg 0.0914), current_reward: 0.5900 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 3800, elapsed time: 353 (avg 0.0925), current_reward: 0.4960 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 3820, elapsed time: 355 (avg 0.0943), current_reward: 0.5390 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 3840, elapsed time: 357 (avg 0.0904), current_reward: 0.5120 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 3860, elapsed time: 359 (avg 0.0880), current_reward: 0.5250 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 3880, elapsed time: 361 (avg 0.0921), current_reward: 0.3770 Action mean: [0.37] Action std: [0.48280430818293246]
Episode 3900, elapsed time: 363 (avg 0.0902), current_reward: 0.5975 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 3920, elapsed time: 364 (avg 0.0901), current_reward: 0.4530 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 3940, elapsed time: 366 (avg 0.0907), current_reward: 0.5180 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 3960, elapsed time: 368 (avg 0.0904), current_reward: 0.4615 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 3980, elapsed time: 370 (avg 0.0894), current_reward: 0.5460 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 4000, elapsed time: 372 (avg 0.0906), current_reward: 0.5735 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 4020, elapsed time: 373 (avg 0.0895), current_reward: 0.5415 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 4040, elapsed time: 375 (avg 0.0890), current_reward: 0.4890 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 4060, elapsed time: 377 (avg 0.0899), current_reward: 0.5475 Action mean: [0.45] Action std: [0.49749371855331]
Episode 4080, elapsed time: 379 (avg 0.0899), current_reward: 0.5560 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 4100, elapsed time: 381 (avg 0.0899), current_reward: 0.6055 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 4120, elapsed time: 382 (avg 0.0893), current_reward: 0.4595 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 4140, elapsed time: 384 (avg 0.0900), current_reward: 0.4325 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 4160, elapsed time: 386 (avg 0.0908), current_reward: 0.4825 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 4180, elapsed time: 388 (avg 0.0899), current_reward: 0.4875 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 4200, elapsed time: 390 (avg 0.0890), current_reward: 0.5300 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 4220, elapsed time: 391 (avg 0.0930), current_reward: 0.5255 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 4240, elapsed time: 393 (avg 0.0898), current_reward: 0.4800 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 4260, elapsed time: 395 (avg 0.0954), current_reward: 0.4170 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 4280, elapsed time: 397 (avg 0.0898), current_reward: 0.5430 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4300, elapsed time: 399 (avg 0.0895), current_reward: 0.5320 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 4320, elapsed time: 400 (avg 0.0901), current_reward: 0.4760 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 4340, elapsed time: 402 (avg 0.0923), current_reward: 0.4285 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4360, elapsed time: 404 (avg 0.0900), current_reward: 0.4705 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 4380, elapsed time: 406 (avg 0.0919), current_reward: 0.4630 Action mean: [0.54] Action std: [0.4983974317750845]
Episode 4400, elapsed time: 408 (avg 0.0907), current_reward: 0.5310 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 4420, elapsed time: 410 (avg 0.0886), current_reward: 0.4965 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4440, elapsed time: 411 (avg 0.0893), current_reward: 0.4635 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 4460, elapsed time: 413 (avg 0.0937), current_reward: 0.4655 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 4480, elapsed time: 415 (avg 0.1112), current_reward: 0.4715 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 4500, elapsed time: 417 (avg 0.0943), current_reward: 0.5140 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 4520, elapsed time: 419 (avg 0.0974), current_reward: 0.4885 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 4540, elapsed time: 421 (avg 0.0885), current_reward: 0.4340 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 4560, elapsed time: 423 (avg 0.0995), current_reward: 0.4045 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4580, elapsed time: 426 (avg 0.1320), current_reward: 0.5565 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 4600, elapsed time: 428 (avg 0.1025), current_reward: 0.5375 Action mean: [0.45] Action std: [0.49749371855331]
Episode 4620, elapsed time: 432 (avg 0.1895), current_reward: 0.4905 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 4640, elapsed time: 434 (avg 0.1398), current_reward: 0.4625 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4660, elapsed time: 436 (avg 0.0951), current_reward: 0.5115 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 4680, elapsed time: 438 (avg 0.0968), current_reward: 0.4480 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 4700, elapsed time: 440 (avg 0.0951), current_reward: 0.5980 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 4720, elapsed time: 442 (avg 0.0903), current_reward: 0.5655 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 4740, elapsed time: 444 (avg 0.0913), current_reward: 0.6195 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 4760, elapsed time: 445 (avg 0.0901), current_reward: 0.5025 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 4780, elapsed time: 447 (avg 0.0953), current_reward: 0.5170 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 4800, elapsed time: 449 (avg 0.0932), current_reward: 0.5160 Action mean: [0.5] Action std: [0.5]
Episode 4820, elapsed time: 451 (avg 0.0959), current_reward: 0.4460 Action mean: [0.5] Action std: [0.5]
Episode 4840, elapsed time: 453 (avg 0.0950), current_reward: 0.5245 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 4860, elapsed time: 455 (avg 0.0944), current_reward: 0.4580 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 4880, elapsed time: 457 (avg 0.0970), current_reward: 0.4725 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 4900, elapsed time: 459 (avg 0.0966), current_reward: 0.4945 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 4920, elapsed time: 461 (avg 0.0983), current_reward: 0.5195 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 4940, elapsed time: 463 (avg 0.1067), current_reward: 0.5155 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 4960, elapsed time: 465 (avg 0.1031), current_reward: 0.5945 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 4980, elapsed time: 467 (avg 0.0976), current_reward: 0.4960 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5000, elapsed time: 469 (avg 0.0926), current_reward: 0.4890 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 5020, elapsed time: 471 (avg 0.0950), current_reward: 0.4505 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 5040, elapsed time: 473 (avg 0.0913), current_reward: 0.4960 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 5060, elapsed time: 474 (avg 0.0929), current_reward: 0.4995 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5080, elapsed time: 476 (avg 0.0967), current_reward: 0.5665 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 5100, elapsed time: 478 (avg 0.0940), current_reward: 0.5380 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5120, elapsed time: 480 (avg 0.0871), current_reward: 0.5510 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 5140, elapsed time: 482 (avg 0.0955), current_reward: 0.5480 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 5160, elapsed time: 484 (avg 0.1081), current_reward: 0.6120 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 5180, elapsed time: 486 (avg 0.0966), current_reward: 0.6245 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5200, elapsed time: 488 (avg 0.1004), current_reward: 0.5205 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 5220, elapsed time: 490 (avg 0.0965), current_reward: 0.4865 Action mean: [0.5] Action std: [0.5]
Episode 5240, elapsed time: 492 (avg 0.0921), current_reward: 0.4820 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 5260, elapsed time: 493 (avg 0.0879), current_reward: 0.5850 Action mean: [0.45] Action std: [0.49749371855331]
Episode 5280, elapsed time: 495 (avg 0.0871), current_reward: 0.5175 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 5300, elapsed time: 497 (avg 0.0867), current_reward: 0.5345 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5320, elapsed time: 499 (avg 0.0868), current_reward: 0.5435 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 5340, elapsed time: 500 (avg 0.0868), current_reward: 0.4470 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 5360, elapsed time: 502 (avg 0.0865), current_reward: 0.4475 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 5380, elapsed time: 504 (avg 0.0865), current_reward: 0.4655 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 5400, elapsed time: 506 (avg 0.0865), current_reward: 0.5420 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 5420, elapsed time: 507 (avg 0.0869), current_reward: 0.4970 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5440, elapsed time: 509 (avg 0.0873), current_reward: 0.5000 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 5460, elapsed time: 511 (avg 0.0883), current_reward: 0.5000 Action mean: [0.36] Action std: [0.48]
Episode 5480, elapsed time: 513 (avg 0.0868), current_reward: 0.4855 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 5500, elapsed time: 514 (avg 0.0865), current_reward: 0.3865 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 5520, elapsed time: 516 (avg 0.0867), current_reward: 0.5040 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 5540, elapsed time: 518 (avg 0.0867), current_reward: 0.5580 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 5560, elapsed time: 520 (avg 0.0868), current_reward: 0.5280 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 5580, elapsed time: 521 (avg 0.0868), current_reward: 0.4850 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 5600, elapsed time: 523 (avg 0.0867), current_reward: 0.4150 Action mean: [0.5] Action std: [0.5]
Episode 5620, elapsed time: 525 (avg 0.0866), current_reward: 0.4735 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 5640, elapsed time: 526 (avg 0.0866), current_reward: 0.4900 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 5660, elapsed time: 528 (avg 0.0872), current_reward: 0.3560 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 5680, elapsed time: 530 (avg 0.0867), current_reward: 0.4560 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 5700, elapsed time: 532 (avg 0.0870), current_reward: 0.5285 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 5720, elapsed time: 534 (avg 0.0917), current_reward: 0.4670 Action mean: [0.4] Action std: [0.4898979485566357]
Episode 5740, elapsed time: 535 (avg 0.0874), current_reward: 0.5140 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 5760, elapsed time: 537 (avg 0.0866), current_reward: 0.4765 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 5780, elapsed time: 539 (avg 0.0933), current_reward: 0.4725 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 5800, elapsed time: 541 (avg 0.0923), current_reward: 0.4720 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 5820, elapsed time: 543 (avg 0.0921), current_reward: 0.4225 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 5840, elapsed time: 544 (avg 0.0901), current_reward: 0.5175 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 5860, elapsed time: 546 (avg 0.0928), current_reward: 0.4620 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 5880, elapsed time: 548 (avg 0.0899), current_reward: 0.5420 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 5900, elapsed time: 550 (avg 0.0898), current_reward: 0.5505 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 5920, elapsed time: 552 (avg 0.0944), current_reward: 0.5225 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 5940, elapsed time: 554 (avg 0.0921), current_reward: 0.3750 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 5960, elapsed time: 556 (avg 0.0986), current_reward: 0.5530 Action mean: [0.34] Action std: [0.4737087712930804]
Episode 5980, elapsed time: 557 (avg 0.0978), current_reward: 0.4780 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 6000, elapsed time: 559 (avg 0.0903), current_reward: 0.4855 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 6020, elapsed time: 561 (avg 0.0938), current_reward: 0.5070 Action mean: [0.36] Action std: [0.48]
Episode 6040, elapsed time: 563 (avg 0.0924), current_reward: 0.4805 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 6060, elapsed time: 565 (avg 0.0972), current_reward: 0.4825 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 6080, elapsed time: 567 (avg 0.0968), current_reward: 0.4495 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 6100, elapsed time: 569 (avg 0.1029), current_reward: 0.5530 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 6120, elapsed time: 571 (avg 0.0949), current_reward: 0.5890 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 6140, elapsed time: 573 (avg 0.0950), current_reward: 0.4855 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 6160, elapsed time: 575 (avg 0.0954), current_reward: 0.4765 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 6180, elapsed time: 577 (avg 0.1005), current_reward: 0.5355 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 6200, elapsed time: 579 (avg 0.0974), current_reward: 0.5420 Action mean: [0.36] Action std: [0.48]
Episode 6220, elapsed time: 580 (avg 0.0945), current_reward: 0.5620 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 6240, elapsed time: 582 (avg 0.0904), current_reward: 0.4120 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6260, elapsed time: 584 (avg 0.0894), current_reward: 0.5385 Action mean: [0.43] Action std: [0.49507575177946245]
Episode 6280, elapsed time: 586 (avg 0.0903), current_reward: 0.5350 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 6300, elapsed time: 588 (avg 0.1002), current_reward: 0.5325 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 6320, elapsed time: 590 (avg 0.0958), current_reward: 0.5145 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 6340, elapsed time: 592 (avg 0.0945), current_reward: 0.5585 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 6360, elapsed time: 594 (avg 0.0960), current_reward: 0.5100 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6380, elapsed time: 595 (avg 0.0897), current_reward: 0.4515 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 6400, elapsed time: 597 (avg 0.0893), current_reward: 0.5930 Action mean: [0.55] Action std: [0.49749371855331]
Episode 6420, elapsed time: 599 (avg 0.0895), current_reward: 0.5605 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6440, elapsed time: 601 (avg 0.0916), current_reward: 0.4840 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 6460, elapsed time: 603 (avg 0.0932), current_reward: 0.4635 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 6480, elapsed time: 605 (avg 0.0949), current_reward: 0.5045 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 6500, elapsed time: 606 (avg 0.0883), current_reward: 0.5135 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 6520, elapsed time: 608 (avg 0.0890), current_reward: 0.5455 Action mean: [0.55] Action std: [0.49749371855331]
Episode 6540, elapsed time: 610 (avg 0.0885), current_reward: 0.5915 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 6560, elapsed time: 612 (avg 0.0883), current_reward: 0.4840 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6580, elapsed time: 613 (avg 0.0884), current_reward: 0.5030 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 6600, elapsed time: 615 (avg 0.0888), current_reward: 0.4550 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 6620, elapsed time: 617 (avg 0.0885), current_reward: 0.5775 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 6640, elapsed time: 619 (avg 0.0884), current_reward: 0.5070 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 6660, elapsed time: 621 (avg 0.0881), current_reward: 0.5020 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 6680, elapsed time: 622 (avg 0.0888), current_reward: 0.4800 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 6700, elapsed time: 624 (avg 0.0882), current_reward: 0.4800 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 6720, elapsed time: 626 (avg 0.0884), current_reward: 0.5140 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 6740, elapsed time: 628 (avg 0.0887), current_reward: 0.5460 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6760, elapsed time: 630 (avg 0.0960), current_reward: 0.5150 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 6780, elapsed time: 631 (avg 0.0933), current_reward: 0.4830 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 6800, elapsed time: 633 (avg 0.0956), current_reward: 0.4995 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 6820, elapsed time: 635 (avg 0.0915), current_reward: 0.5200 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 6840, elapsed time: 637 (avg 0.0909), current_reward: 0.5850 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 6860, elapsed time: 639 (avg 0.0923), current_reward: 0.5505 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 6880, elapsed time: 641 (avg 0.0924), current_reward: 0.4240 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 6900, elapsed time: 642 (avg 0.0922), current_reward: 0.5210 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 6920, elapsed time: 644 (avg 0.0938), current_reward: 0.4900 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 6940, elapsed time: 646 (avg 0.0947), current_reward: 0.4525 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 6960, elapsed time: 648 (avg 0.0928), current_reward: 0.4535 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 6980, elapsed time: 650 (avg 0.0927), current_reward: 0.4610 Action mean: [0.38] Action std: [0.4853864439804639]
Episode 7000, elapsed time: 652 (avg 0.0906), current_reward: 0.5690 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 7020, elapsed time: 654 (avg 0.0915), current_reward: 0.4910 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 7040, elapsed time: 655 (avg 0.0898), current_reward: 0.4855 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 7060, elapsed time: 657 (avg 0.0890), current_reward: 0.4700 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 7080, elapsed time: 659 (avg 0.0950), current_reward: 0.6025 Action mean: [0.5] Action std: [0.5]
Episode 7100, elapsed time: 661 (avg 0.0991), current_reward: 0.5255 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 7120, elapsed time: 663 (avg 0.0929), current_reward: 0.4010 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 7140, elapsed time: 665 (avg 0.0880), current_reward: 0.4560 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 7160, elapsed time: 666 (avg 0.0886), current_reward: 0.5370 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 7180, elapsed time: 668 (avg 0.0947), current_reward: 0.4225 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 7200, elapsed time: 670 (avg 0.0949), current_reward: 0.4750 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 7220, elapsed time: 672 (avg 0.0941), current_reward: 0.4915 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 7240, elapsed time: 674 (avg 0.0925), current_reward: 0.4775 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 7260, elapsed time: 676 (avg 0.0901), current_reward: 0.4480 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 7280, elapsed time: 678 (avg 0.0920), current_reward: 0.6020 Action mean: [0.59] Action std: [0.4918333050943175]
Episode 7300, elapsed time: 679 (avg 0.0931), current_reward: 0.5480 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 7320, elapsed time: 681 (avg 0.0938), current_reward: 0.5155 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 7340, elapsed time: 683 (avg 0.0934), current_reward: 0.4890 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 7360, elapsed time: 685 (avg 0.0942), current_reward: 0.4490 Action mean: [0.5] Action std: [0.5]
Episode 7380, elapsed time: 687 (avg 0.0933), current_reward: 0.5010 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 7400, elapsed time: 689 (avg 0.1000), current_reward: 0.4775 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 7420, elapsed time: 691 (avg 0.1003), current_reward: 0.4325 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 7440, elapsed time: 693 (avg 0.0886), current_reward: 0.5425 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 7460, elapsed time: 695 (avg 0.0975), current_reward: 0.5560 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 7480, elapsed time: 697 (avg 0.0933), current_reward: 0.5035 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 7500, elapsed time: 698 (avg 0.0966), current_reward: 0.4640 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 7520, elapsed time: 700 (avg 0.0956), current_reward: 0.5155 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 7540, elapsed time: 702 (avg 0.0945), current_reward: 0.5030 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 7560, elapsed time: 704 (avg 0.0903), current_reward: 0.4350 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 7580, elapsed time: 706 (avg 0.0959), current_reward: 0.3790 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 7600, elapsed time: 708 (avg 0.1000), current_reward: 0.4455 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 7620, elapsed time: 710 (avg 0.0938), current_reward: 0.4355 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 7640, elapsed time: 712 (avg 0.0911), current_reward: 0.4290 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 7660, elapsed time: 714 (avg 0.0919), current_reward: 0.4995 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 7680, elapsed time: 715 (avg 0.0912), current_reward: 0.5915 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 7700, elapsed time: 717 (avg 0.1015), current_reward: 0.4025 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 7720, elapsed time: 719 (avg 0.0994), current_reward: 0.4870 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 7740, elapsed time: 721 (avg 0.1003), current_reward: 0.4825 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 7760, elapsed time: 723 (avg 0.0968), current_reward: 0.5290 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 7780, elapsed time: 725 (avg 0.0910), current_reward: 0.5050 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 7800, elapsed time: 727 (avg 0.0903), current_reward: 0.5355 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 7820, elapsed time: 729 (avg 0.0921), current_reward: 0.4575 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 7840, elapsed time: 731 (avg 0.0955), current_reward: 0.5610 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 7860, elapsed time: 733 (avg 0.0965), current_reward: 0.4505 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 7880, elapsed time: 734 (avg 0.0923), current_reward: 0.5690 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 7900, elapsed time: 736 (avg 0.0918), current_reward: 0.4795 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 7920, elapsed time: 738 (avg 0.0909), current_reward: 0.5210 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 7940, elapsed time: 740 (avg 0.0925), current_reward: 0.4700 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 7960, elapsed time: 742 (avg 0.1162), current_reward: 0.4405 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 7980, elapsed time: 744 (avg 0.0908), current_reward: 0.5050 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8000, elapsed time: 746 (avg 0.0906), current_reward: 0.4940 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 8020, elapsed time: 748 (avg 0.0902), current_reward: 0.4620 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 8040, elapsed time: 750 (avg 0.0900), current_reward: 0.5330 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 8060, elapsed time: 751 (avg 0.0906), current_reward: 0.5055 Action mean: [0.5] Action std: [0.5]
Episode 8080, elapsed time: 753 (avg 0.0901), current_reward: 0.5100 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8100, elapsed time: 755 (avg 0.0903), current_reward: 0.5105 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 8120, elapsed time: 757 (avg 0.0899), current_reward: 0.4515 Action mean: [0.5] Action std: [0.5]
Episode 8140, elapsed time: 759 (avg 0.0910), current_reward: 0.5365 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 8160, elapsed time: 760 (avg 0.0949), current_reward: 0.5860 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8180, elapsed time: 762 (avg 0.0980), current_reward: 0.4575 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 8200, elapsed time: 764 (avg 0.0896), current_reward: 0.5230 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 8220, elapsed time: 766 (avg 0.0875), current_reward: 0.4950 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 8240, elapsed time: 768 (avg 0.0898), current_reward: 0.5330 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8260, elapsed time: 770 (avg 0.0892), current_reward: 0.6350 Action mean: [0.5] Action std: [0.5]
Episode 8280, elapsed time: 771 (avg 0.0884), current_reward: 0.4365 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 8300, elapsed time: 773 (avg 0.0917), current_reward: 0.5455 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 8320, elapsed time: 775 (avg 0.1086), current_reward: 0.3855 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 8340, elapsed time: 778 (avg 0.1088), current_reward: 0.6055 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 8360, elapsed time: 779 (avg 0.0922), current_reward: 0.4685 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 8380, elapsed time: 781 (avg 0.0917), current_reward: 0.4720 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 8400, elapsed time: 783 (avg 0.0972), current_reward: 0.4870 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8420, elapsed time: 785 (avg 0.1071), current_reward: 0.5580 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 8440, elapsed time: 787 (avg 0.0962), current_reward: 0.4155 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 8460, elapsed time: 790 (avg 0.1458), current_reward: 0.4620 Action mean: [0.56] Action std: [0.4963869458396343]
Episode 8480, elapsed time: 792 (avg 0.1095), current_reward: 0.5225 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 8500, elapsed time: 794 (avg 0.1060), current_reward: 0.5160 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 8520, elapsed time: 796 (avg 0.0943), current_reward: 0.4110 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 8540, elapsed time: 798 (avg 0.0962), current_reward: 0.4510 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8560, elapsed time: 800 (avg 0.0987), current_reward: 0.5430 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 8580, elapsed time: 802 (avg 0.1077), current_reward: 0.4650 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 8600, elapsed time: 804 (avg 0.1019), current_reward: 0.4965 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 8620, elapsed time: 806 (avg 0.0939), current_reward: 0.4125 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 8640, elapsed time: 808 (avg 0.0959), current_reward: 0.5825 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 8660, elapsed time: 810 (avg 0.1103), current_reward: 0.4890 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8680, elapsed time: 812 (avg 0.1007), current_reward: 0.4940 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 8700, elapsed time: 814 (avg 0.1009), current_reward: 0.4860 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 8720, elapsed time: 816 (avg 0.1004), current_reward: 0.5790 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 8740, elapsed time: 819 (avg 0.1215), current_reward: 0.5180 Action mean: [0.45] Action std: [0.49749371855331]
Episode 8760, elapsed time: 822 (avg 0.1381), current_reward: 0.4890 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 8780, elapsed time: 825 (avg 0.1448), current_reward: 0.5220 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 8800, elapsed time: 827 (avg 0.1040), current_reward: 0.5010 Action mean: [0.5] Action std: [0.5]
Episode 8820, elapsed time: 829 (avg 0.0954), current_reward: 0.4840 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 8840, elapsed time: 831 (avg 0.0990), current_reward: 0.4960 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 8860, elapsed time: 833 (avg 0.1049), current_reward: 0.5310 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 8880, elapsed time: 835 (avg 0.1103), current_reward: 0.4815 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 8900, elapsed time: 837 (avg 0.0933), current_reward: 0.4620 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 8920, elapsed time: 839 (avg 0.0918), current_reward: 0.5425 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 8940, elapsed time: 840 (avg 0.0902), current_reward: 0.4735 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 8960, elapsed time: 842 (avg 0.0916), current_reward: 0.4385 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 8980, elapsed time: 844 (avg 0.0901), current_reward: 0.5195 Action mean: [0.5] Action std: [0.5]
Episode 9000, elapsed time: 846 (avg 0.0890), current_reward: 0.5020 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 9020, elapsed time: 848 (avg 0.0889), current_reward: 0.4850 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 9040, elapsed time: 849 (avg 0.0937), current_reward: 0.5865 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 9060, elapsed time: 851 (avg 0.0932), current_reward: 0.4570 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 9080, elapsed time: 853 (avg 0.0925), current_reward: 0.4680 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 9100, elapsed time: 855 (avg 0.0916), current_reward: 0.6055 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 9120, elapsed time: 857 (avg 0.0908), current_reward: 0.5720 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 9140, elapsed time: 859 (avg 0.0902), current_reward: 0.4975 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 9160, elapsed time: 860 (avg 0.0949), current_reward: 0.4765 Action mean: [0.45] Action std: [0.49749371855331]
Episode 9180, elapsed time: 862 (avg 0.0963), current_reward: 0.5395 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 9200, elapsed time: 864 (avg 0.0959), current_reward: 0.5145 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 9220, elapsed time: 866 (avg 0.0954), current_reward: 0.5835 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 9240, elapsed time: 868 (avg 0.1019), current_reward: 0.5620 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 9260, elapsed time: 870 (avg 0.0942), current_reward: 0.5590 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 9280, elapsed time: 872 (avg 0.0921), current_reward: 0.6150 Action mean: [0.45] Action std: [0.49749371855331]
Episode 9300, elapsed time: 874 (avg 0.0901), current_reward: 0.4955 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 9320, elapsed time: 876 (avg 0.0905), current_reward: 0.5195 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 9340, elapsed time: 877 (avg 0.0892), current_reward: 0.4965 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 9360, elapsed time: 879 (avg 0.0888), current_reward: 0.5635 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 9380, elapsed time: 881 (avg 0.0877), current_reward: 0.5315 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 9400, elapsed time: 883 (avg 0.0879), current_reward: 0.5285 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 9420, elapsed time: 884 (avg 0.0877), current_reward: 0.5680 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 9440, elapsed time: 886 (avg 0.0879), current_reward: 0.5630 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 9460, elapsed time: 888 (avg 0.0886), current_reward: 0.4940 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 9480, elapsed time: 890 (avg 0.0881), current_reward: 0.5060 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 9500, elapsed time: 891 (avg 0.0884), current_reward: 0.4710 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 9520, elapsed time: 893 (avg 0.0884), current_reward: 0.3650 Action mean: [0.45] Action std: [0.49749371855331]
Episode 9540, elapsed time: 895 (avg 0.0926), current_reward: 0.5690 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 9560, elapsed time: 897 (avg 0.0882), current_reward: 0.4400 Action mean: [0.38] Action std: [0.4853864439804639]
Episode 9580, elapsed time: 899 (avg 0.1066), current_reward: 0.4875 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 9600, elapsed time: 901 (avg 0.0900), current_reward: 0.4170 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 9620, elapsed time: 903 (avg 0.0907), current_reward: 0.5085 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 9640, elapsed time: 905 (avg 0.0972), current_reward: 0.5145 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 9660, elapsed time: 906 (avg 0.0894), current_reward: 0.4665 Action mean: [0.56] Action std: [0.4963869458396343]
Episode 9680, elapsed time: 908 (avg 0.0872), current_reward: 0.5175 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 9700, elapsed time: 910 (avg 0.0876), current_reward: 0.4935 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 9720, elapsed time: 912 (avg 0.0865), current_reward: 0.5465 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 9740, elapsed time: 913 (avg 0.0935), current_reward: 0.4540 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 9760, elapsed time: 915 (avg 0.0879), current_reward: 0.4725 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 9780, elapsed time: 917 (avg 0.0885), current_reward: 0.5215 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 9800, elapsed time: 919 (avg 0.0911), current_reward: 0.5315 Action mean: [0.35] Action std: [0.4769696007084727]
Episode 9820, elapsed time: 921 (avg 0.0921), current_reward: 0.4780 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 9840, elapsed time: 922 (avg 0.0915), current_reward: 0.5200 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 9860, elapsed time: 924 (avg 0.0901), current_reward: 0.4335 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 9880, elapsed time: 926 (avg 0.0915), current_reward: 0.4895 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 9900, elapsed time: 928 (avg 0.0891), current_reward: 0.5160 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 9920, elapsed time: 930 (avg 0.0899), current_reward: 0.5200 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 9940, elapsed time: 932 (avg 0.0933), current_reward: 0.5825 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 9960, elapsed time: 933 (avg 0.0942), current_reward: 0.4655 Action mean: [0.5] Action std: [0.5]
Episode 9980, elapsed time: 935 (avg 0.0963), current_reward: 0.4615 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 10000, elapsed time: 937 (avg 0.0956), current_reward: 0.4935 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 10020, elapsed time: 939 (avg 0.0968), current_reward: 0.4765 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 10040, elapsed time: 941 (avg 0.1057), current_reward: 0.5500 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 10060, elapsed time: 943 (avg 0.0909), current_reward: 0.5240 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 10080, elapsed time: 945 (avg 0.0964), current_reward: 0.4775 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 10100, elapsed time: 947 (avg 0.0943), current_reward: 0.4755 Action mean: [0.49] Action std: [0.4998999899979994]
Episode 10120, elapsed time: 949 (avg 0.0916), current_reward: 0.4995 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 10140, elapsed time: 951 (avg 0.0967), current_reward: 0.4700 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 10160, elapsed time: 953 (avg 0.1000), current_reward: 0.5565 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 10180, elapsed time: 955 (avg 0.0931), current_reward: 0.4670 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 10200, elapsed time: 957 (avg 0.1001), current_reward: 0.5605 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 10220, elapsed time: 958 (avg 0.0962), current_reward: 0.4780 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 10240, elapsed time: 960 (avg 0.0961), current_reward: 0.4940 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 10260, elapsed time: 962 (avg 0.0963), current_reward: 0.4640 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 10280, elapsed time: 964 (avg 0.0942), current_reward: 0.4330 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 10300, elapsed time: 966 (avg 0.0889), current_reward: 0.4910 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 10320, elapsed time: 968 (avg 0.0901), current_reward: 0.5595 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 10340, elapsed time: 970 (avg 0.0978), current_reward: 0.4780 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 10360, elapsed time: 972 (avg 0.0999), current_reward: 0.5065 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 10380, elapsed time: 974 (avg 0.1069), current_reward: 0.4970 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 10400, elapsed time: 976 (avg 0.0944), current_reward: 0.4890 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 10420, elapsed time: 978 (avg 0.0924), current_reward: 0.5460 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 10440, elapsed time: 979 (avg 0.0920), current_reward: 0.4910 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 10460, elapsed time: 981 (avg 0.0971), current_reward: 0.4370 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 10480, elapsed time: 984 (avg 0.1123), current_reward: 0.5540 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 10500, elapsed time: 986 (avg 0.0989), current_reward: 0.4940 Action mean: [0.45] Action std: [0.49749371855331]
Episode 10520, elapsed time: 988 (avg 0.1083), current_reward: 0.5385 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 10540, elapsed time: 990 (avg 0.0996), current_reward: 0.4575 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 10560, elapsed time: 992 (avg 0.0946), current_reward: 0.5225 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 10580, elapsed time: 994 (avg 0.0942), current_reward: 0.6060 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 10600, elapsed time: 995 (avg 0.0921), current_reward: 0.5065 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 10620, elapsed time: 997 (avg 0.1024), current_reward: 0.5000 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 10640, elapsed time: 999 (avg 0.0904), current_reward: 0.5490 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 10660, elapsed time: 1001 (avg 0.0907), current_reward: 0.4580 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 10680, elapsed time: 1003 (avg 0.0907), current_reward: 0.5305 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 10700, elapsed time: 1005 (avg 0.0900), current_reward: 0.5315 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 10720, elapsed time: 1007 (avg 0.0919), current_reward: 0.5160 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 10740, elapsed time: 1009 (avg 0.1020), current_reward: 0.4685 Action mean: [0.49] Action std: [0.49989998999799956]
Episode 10760, elapsed time: 1011 (avg 0.1021), current_reward: 0.5315 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 10780, elapsed time: 1012 (avg 0.0932), current_reward: 0.5060 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 10800, elapsed time: 1014 (avg 0.0890), current_reward: 0.5025 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 10820, elapsed time: 1016 (avg 0.0882), current_reward: 0.5055 Action mean: [0.32] Action std: [0.46647615158762396]
Episode 10840, elapsed time: 1018 (avg 0.0880), current_reward: 0.4885 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 10860, elapsed time: 1020 (avg 0.0884), current_reward: 0.4660 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 10880, elapsed time: 1021 (avg 0.0879), current_reward: 0.5125 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 10900, elapsed time: 1023 (avg 0.0939), current_reward: 0.5520 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 10920, elapsed time: 1025 (avg 0.0902), current_reward: 0.5290 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 10940, elapsed time: 1027 (avg 0.1084), current_reward: 0.4710 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 10960, elapsed time: 1029 (avg 0.0903), current_reward: 0.4540 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 10980, elapsed time: 1031 (avg 0.0951), current_reward: 0.5455 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 11000, elapsed time: 1033 (avg 0.1050), current_reward: 0.5390 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 11020, elapsed time: 1035 (avg 0.0882), current_reward: 0.5145 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 11040, elapsed time: 1036 (avg 0.0875), current_reward: 0.4840 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 11060, elapsed time: 1038 (avg 0.0866), current_reward: 0.4180 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 11080, elapsed time: 1040 (avg 0.0867), current_reward: 0.4445 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 11100, elapsed time: 1042 (avg 0.0883), current_reward: 0.4295 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 11120, elapsed time: 1043 (avg 0.0878), current_reward: 0.4905 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 11140, elapsed time: 1045 (avg 0.0891), current_reward: 0.4725 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11160, elapsed time: 1047 (avg 0.0886), current_reward: 0.4460 Action mean: [0.45] Action std: [0.49749371855331]
Episode 11180, elapsed time: 1049 (avg 0.0886), current_reward: 0.4730 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 11200, elapsed time: 1051 (avg 0.0903), current_reward: 0.4050 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 11220, elapsed time: 1053 (avg 0.0964), current_reward: 0.5175 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11240, elapsed time: 1054 (avg 0.0987), current_reward: 0.6060 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 11260, elapsed time: 1056 (avg 0.0915), current_reward: 0.5185 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 11280, elapsed time: 1058 (avg 0.0985), current_reward: 0.4250 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 11300, elapsed time: 1060 (avg 0.0958), current_reward: 0.5095 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 11320, elapsed time: 1062 (avg 0.0934), current_reward: 0.4740 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 11340, elapsed time: 1064 (avg 0.0918), current_reward: 0.5115 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 11360, elapsed time: 1066 (avg 0.0933), current_reward: 0.4620 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 11380, elapsed time: 1068 (avg 0.0956), current_reward: 0.5360 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 11400, elapsed time: 1070 (avg 0.0912), current_reward: 0.4680 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 11420, elapsed time: 1071 (avg 0.0928), current_reward: 0.5030 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 11440, elapsed time: 1073 (avg 0.0889), current_reward: 0.5080 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 11460, elapsed time: 1075 (avg 0.0876), current_reward: 0.5035 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11480, elapsed time: 1077 (avg 0.0883), current_reward: 0.4125 Action mean: [0.5] Action std: [0.5]
Episode 11500, elapsed time: 1078 (avg 0.0890), current_reward: 0.5100 Action mean: [0.38] Action std: [0.485386443980464]
Episode 11520, elapsed time: 1080 (avg 0.0877), current_reward: 0.5145 Action mean: [0.39] Action std: [0.487749935930288]
Episode 11540, elapsed time: 1082 (avg 0.0885), current_reward: 0.4980 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 11560, elapsed time: 1084 (avg 0.0879), current_reward: 0.4760 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 11580, elapsed time: 1085 (avg 0.0882), current_reward: 0.5225 Action mean: [0.36] Action std: [0.48]
Episode 11600, elapsed time: 1087 (avg 0.0903), current_reward: 0.5650 Action mean: [0.45] Action std: [0.49749371855331]
Episode 11620, elapsed time: 1089 (avg 0.0899), current_reward: 0.4675 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11640, elapsed time: 1091 (avg 0.0888), current_reward: 0.5520 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 11660, elapsed time: 1093 (avg 0.0886), current_reward: 0.5225 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11680, elapsed time: 1094 (avg 0.0881), current_reward: 0.4410 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 11700, elapsed time: 1096 (avg 0.0893), current_reward: 0.3865 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11720, elapsed time: 1098 (avg 0.0881), current_reward: 0.4690 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 11740, elapsed time: 1100 (avg 0.0881), current_reward: 0.5205 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11760, elapsed time: 1101 (avg 0.0879), current_reward: 0.4595 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 11780, elapsed time: 1103 (avg 0.0879), current_reward: 0.4710 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 11800, elapsed time: 1105 (avg 0.0887), current_reward: 0.4115 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 11820, elapsed time: 1107 (avg 0.0917), current_reward: 0.4920 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 11840, elapsed time: 1109 (avg 0.0890), current_reward: 0.4640 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 11860, elapsed time: 1110 (avg 0.0882), current_reward: 0.4880 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 11880, elapsed time: 1112 (avg 0.0908), current_reward: 0.4545 Action mean: [0.5] Action std: [0.5]
Episode 11900, elapsed time: 1114 (avg 0.0930), current_reward: 0.5140 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 11920, elapsed time: 1116 (avg 0.0901), current_reward: 0.4970 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 11940, elapsed time: 1118 (avg 0.0944), current_reward: 0.4910 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 11960, elapsed time: 1120 (avg 0.0901), current_reward: 0.4540 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 11980, elapsed time: 1122 (avg 0.0990), current_reward: 0.4605 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 12000, elapsed time: 1123 (avg 0.0924), current_reward: 0.4635 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 12020, elapsed time: 1125 (avg 0.0947), current_reward: 0.5890 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 12040, elapsed time: 1127 (avg 0.0949), current_reward: 0.5035 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 12060, elapsed time: 1129 (avg 0.0937), current_reward: 0.4920 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12080, elapsed time: 1131 (avg 0.0916), current_reward: 0.4915 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 12100, elapsed time: 1133 (avg 0.0991), current_reward: 0.5055 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12120, elapsed time: 1135 (avg 0.0908), current_reward: 0.4960 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12140, elapsed time: 1136 (avg 0.0901), current_reward: 0.4755 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 12160, elapsed time: 1138 (avg 0.0971), current_reward: 0.4935 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 12180, elapsed time: 1140 (avg 0.0949), current_reward: 0.4985 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 12200, elapsed time: 1142 (avg 0.0953), current_reward: 0.4670 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 12220, elapsed time: 1144 (avg 0.0863), current_reward: 0.5655 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 12240, elapsed time: 1146 (avg 0.0897), current_reward: 0.5290 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12260, elapsed time: 1148 (avg 0.0927), current_reward: 0.5595 Action mean: [0.5] Action std: [0.5]
Episode 12280, elapsed time: 1149 (avg 0.0929), current_reward: 0.4815 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 12300, elapsed time: 1151 (avg 0.0880), current_reward: 0.4665 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 12320, elapsed time: 1153 (avg 0.0904), current_reward: 0.5530 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 12340, elapsed time: 1155 (avg 0.0905), current_reward: 0.4875 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12360, elapsed time: 1157 (avg 0.0985), current_reward: 0.4705 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 12380, elapsed time: 1159 (avg 0.0951), current_reward: 0.5070 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 12400, elapsed time: 1161 (avg 0.0970), current_reward: 0.3855 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 12420, elapsed time: 1163 (avg 0.0972), current_reward: 0.4685 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12440, elapsed time: 1164 (avg 0.0952), current_reward: 0.4670 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 12460, elapsed time: 1166 (avg 0.0942), current_reward: 0.4950 Action mean: [0.45] Action std: [0.49749371855331]
Episode 12480, elapsed time: 1168 (avg 0.1005), current_reward: 0.5065 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 12500, elapsed time: 1170 (avg 0.0992), current_reward: 0.5415 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 12520, elapsed time: 1172 (avg 0.0892), current_reward: 0.5105 Action mean: [0.5] Action std: [0.5]
Episode 12540, elapsed time: 1174 (avg 0.0973), current_reward: 0.4350 Action mean: [0.34] Action std: [0.4737087712930805]
Episode 12560, elapsed time: 1176 (avg 0.1050), current_reward: 0.5240 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 12580, elapsed time: 1178 (avg 0.1063), current_reward: 0.4745 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 12600, elapsed time: 1180 (avg 0.1027), current_reward: 0.4555 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 12620, elapsed time: 1182 (avg 0.0921), current_reward: 0.5065 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 12640, elapsed time: 1184 (avg 0.0895), current_reward: 0.4860 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 12660, elapsed time: 1186 (avg 0.0865), current_reward: 0.4930 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 12680, elapsed time: 1188 (avg 0.0924), current_reward: 0.4845 Action mean: [0.55] Action std: [0.49749371855331]
Episode 12700, elapsed time: 1190 (avg 0.0966), current_reward: 0.5455 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 12720, elapsed time: 1192 (avg 0.1195), current_reward: 0.4550 Action mean: [0.36] Action std: [0.48]
Episode 12740, elapsed time: 1194 (avg 0.1121), current_reward: 0.5760 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 12760, elapsed time: 1196 (avg 0.0941), current_reward: 0.4820 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 12780, elapsed time: 1198 (avg 0.0933), current_reward: 0.5160 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 12800, elapsed time: 1200 (avg 0.1087), current_reward: 0.6040 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 12820, elapsed time: 1202 (avg 0.1028), current_reward: 0.5675 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 12840, elapsed time: 1204 (avg 0.0895), current_reward: 0.5225 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 12860, elapsed time: 1206 (avg 0.1208), current_reward: 0.5325 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 12880, elapsed time: 1208 (avg 0.0949), current_reward: 0.5825 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12900, elapsed time: 1210 (avg 0.0964), current_reward: 0.4175 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 12920, elapsed time: 1212 (avg 0.0994), current_reward: 0.4505 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 12940, elapsed time: 1214 (avg 0.0915), current_reward: 0.5520 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 12960, elapsed time: 1216 (avg 0.0928), current_reward: 0.4955 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 12980, elapsed time: 1218 (avg 0.0922), current_reward: 0.4755 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 13000, elapsed time: 1220 (avg 0.0902), current_reward: 0.4460 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13020, elapsed time: 1221 (avg 0.0934), current_reward: 0.4590 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 13040, elapsed time: 1223 (avg 0.0918), current_reward: 0.4470 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 13060, elapsed time: 1225 (avg 0.0914), current_reward: 0.5055 Action mean: [0.5] Action std: [0.5]
Episode 13080, elapsed time: 1228 (avg 0.1306), current_reward: 0.4530 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 13100, elapsed time: 1230 (avg 0.1036), current_reward: 0.5020 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 13120, elapsed time: 1232 (avg 0.1084), current_reward: 0.4025 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 13140, elapsed time: 1234 (avg 0.1035), current_reward: 0.5035 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 13160, elapsed time: 1236 (avg 0.1025), current_reward: 0.6245 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 13180, elapsed time: 1238 (avg 0.1073), current_reward: 0.5075 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13200, elapsed time: 1240 (avg 0.1109), current_reward: 0.4595 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13220, elapsed time: 1242 (avg 0.1040), current_reward: 0.4795 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13240, elapsed time: 1244 (avg 0.0980), current_reward: 0.4580 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 13260, elapsed time: 1246 (avg 0.1029), current_reward: 0.3875 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 13280, elapsed time: 1248 (avg 0.0923), current_reward: 0.5230 Action mean: [0.36] Action std: [0.48]
Episode 13300, elapsed time: 1250 (avg 0.0935), current_reward: 0.4895 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 13320, elapsed time: 1252 (avg 0.0958), current_reward: 0.4665 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 13340, elapsed time: 1254 (avg 0.1149), current_reward: 0.5375 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 13360, elapsed time: 1256 (avg 0.0928), current_reward: 0.4750 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 13380, elapsed time: 1258 (avg 0.0890), current_reward: 0.5190 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 13400, elapsed time: 1260 (avg 0.0882), current_reward: 0.5600 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 13420, elapsed time: 1262 (avg 0.0887), current_reward: 0.4915 Action mean: [0.5] Action std: [0.5]
Episode 13440, elapsed time: 1263 (avg 0.0884), current_reward: 0.5290 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13460, elapsed time: 1265 (avg 0.0881), current_reward: 0.5380 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13480, elapsed time: 1267 (avg 0.0915), current_reward: 0.4990 Action mean: [0.39] Action std: [0.487749935930288]
Episode 13500, elapsed time: 1269 (avg 0.1012), current_reward: 0.4855 Action mean: [0.34] Action std: [0.4737087712930804]
Episode 13520, elapsed time: 1271 (avg 0.0922), current_reward: 0.5040 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 13540, elapsed time: 1273 (avg 0.0975), current_reward: 0.5050 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 13560, elapsed time: 1275 (avg 0.0995), current_reward: 0.5280 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 13580, elapsed time: 1276 (avg 0.0877), current_reward: 0.4660 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 13600, elapsed time: 1278 (avg 0.0900), current_reward: 0.5165 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 13620, elapsed time: 1280 (avg 0.0925), current_reward: 0.4810 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 13640, elapsed time: 1282 (avg 0.0921), current_reward: 0.4865 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 13660, elapsed time: 1284 (avg 0.0931), current_reward: 0.5715 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 13680, elapsed time: 1286 (avg 0.1018), current_reward: 0.4310 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 13700, elapsed time: 1288 (avg 0.0926), current_reward: 0.4715 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 13720, elapsed time: 1290 (avg 0.0921), current_reward: 0.4810 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 13740, elapsed time: 1292 (avg 0.1082), current_reward: 0.5015 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 13760, elapsed time: 1294 (avg 0.0988), current_reward: 0.3905 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 13780, elapsed time: 1296 (avg 0.1024), current_reward: 0.4805 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 13800, elapsed time: 1298 (avg 0.0980), current_reward: 0.5210 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 13820, elapsed time: 1300 (avg 0.0934), current_reward: 0.4940 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 13840, elapsed time: 1301 (avg 0.0949), current_reward: 0.4985 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 13860, elapsed time: 1304 (avg 0.1030), current_reward: 0.4630 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 13880, elapsed time: 1305 (avg 0.0891), current_reward: 0.5005 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 13900, elapsed time: 1307 (avg 0.0930), current_reward: 0.4380 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 13920, elapsed time: 1309 (avg 0.1027), current_reward: 0.4880 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 13940, elapsed time: 1311 (avg 0.0977), current_reward: 0.4900 Action mean: [0.32] Action std: [0.46647615158762396]
Episode 13960, elapsed time: 1313 (avg 0.0914), current_reward: 0.5245 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 13980, elapsed time: 1315 (avg 0.0999), current_reward: 0.5310 Action mean: [0.5] Action std: [0.5]
Episode 14000, elapsed time: 1317 (avg 0.0921), current_reward: 0.5365 Action mean: [0.5] Action std: [0.5]
Episode 14020, elapsed time: 1319 (avg 0.0967), current_reward: 0.4915 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 14040, elapsed time: 1321 (avg 0.0955), current_reward: 0.5400 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 14060, elapsed time: 1323 (avg 0.0922), current_reward: 0.4595 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 14080, elapsed time: 1324 (avg 0.0910), current_reward: 0.4275 Action mean: [0.36] Action std: [0.48]
Episode 14100, elapsed time: 1326 (avg 0.0911), current_reward: 0.4790 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 14120, elapsed time: 1328 (avg 0.0894), current_reward: 0.5400 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 14140, elapsed time: 1330 (avg 0.0945), current_reward: 0.5425 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 14160, elapsed time: 1332 (avg 0.0959), current_reward: 0.4080 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 14180, elapsed time: 1334 (avg 0.1101), current_reward: 0.5000 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 14200, elapsed time: 1336 (avg 0.0991), current_reward: 0.5935 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 14220, elapsed time: 1338 (avg 0.0976), current_reward: 0.4860 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 14240, elapsed time: 1340 (avg 0.0949), current_reward: 0.5010 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 14260, elapsed time: 1342 (avg 0.0935), current_reward: 0.4710 Action mean: [0.3] Action std: [0.45825756949558394]
Episode 14280, elapsed time: 1344 (avg 0.1019), current_reward: 0.4945 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 14300, elapsed time: 1346 (avg 0.0958), current_reward: 0.5235 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 14320, elapsed time: 1348 (avg 0.0963), current_reward: 0.5210 Action mean: [0.36] Action std: [0.48]
Episode 14340, elapsed time: 1350 (avg 0.1083), current_reward: 0.4400 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 14360, elapsed time: 1352 (avg 0.0984), current_reward: 0.4420 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 14380, elapsed time: 1354 (avg 0.1007), current_reward: 0.4620 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 14400, elapsed time: 1356 (avg 0.1036), current_reward: 0.5050 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 14420, elapsed time: 1358 (avg 0.1186), current_reward: 0.3980 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 14440, elapsed time: 1360 (avg 0.1046), current_reward: 0.4190 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 14460, elapsed time: 1362 (avg 0.0990), current_reward: 0.4715 Action mean: [0.36] Action std: [0.48]
Episode 14480, elapsed time: 1364 (avg 0.0972), current_reward: 0.5060 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 14500, elapsed time: 1366 (avg 0.0950), current_reward: 0.4845 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 14520, elapsed time: 1368 (avg 0.0921), current_reward: 0.5265 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 14540, elapsed time: 1370 (avg 0.0951), current_reward: 0.4485 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 14560, elapsed time: 1372 (avg 0.0952), current_reward: 0.4800 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 14580, elapsed time: 1374 (avg 0.0930), current_reward: 0.4520 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 14600, elapsed time: 1375 (avg 0.0881), current_reward: 0.4885 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 14620, elapsed time: 1377 (avg 0.0919), current_reward: 0.3985 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 14640, elapsed time: 1379 (avg 0.0922), current_reward: 0.4545 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 14660, elapsed time: 1381 (avg 0.0928), current_reward: 0.5390 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 14680, elapsed time: 1383 (avg 0.0908), current_reward: 0.4900 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 14700, elapsed time: 1385 (avg 0.0918), current_reward: 0.4350 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 14720, elapsed time: 1386 (avg 0.0879), current_reward: 0.4220 Action mean: [0.58] Action std: [0.49355850717012273]
Episode 14740, elapsed time: 1388 (avg 0.0877), current_reward: 0.5085 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 14760, elapsed time: 1390 (avg 0.0883), current_reward: 0.5000 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 14780, elapsed time: 1392 (avg 0.0895), current_reward: 0.4245 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 14800, elapsed time: 1393 (avg 0.0912), current_reward: 0.5575 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 14820, elapsed time: 1395 (avg 0.0875), current_reward: 0.5185 Action mean: [0.39] Action std: [0.487749935930288]
Episode 14840, elapsed time: 1397 (avg 0.0870), current_reward: 0.6020 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 14860, elapsed time: 1399 (avg 0.0873), current_reward: 0.5075 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 14880, elapsed time: 1400 (avg 0.0872), current_reward: 0.5325 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 14900, elapsed time: 1402 (avg 0.0967), current_reward: 0.5100 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 14920, elapsed time: 1404 (avg 0.0875), current_reward: 0.5235 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 14940, elapsed time: 1406 (avg 0.0982), current_reward: 0.4815 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 14960, elapsed time: 1408 (avg 0.0896), current_reward: 0.5035 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 14980, elapsed time: 1410 (avg 0.0965), current_reward: 0.4985 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 15000, elapsed time: 1412 (avg 0.0909), current_reward: 0.5520 Action mean: [0.35] Action std: [0.47696960070847283]
Episode 15020, elapsed time: 1413 (avg 0.0878), current_reward: 0.4705 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 15040, elapsed time: 1415 (avg 0.0873), current_reward: 0.4900 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 15060, elapsed time: 1417 (avg 0.0945), current_reward: 0.4295 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 15080, elapsed time: 1419 (avg 0.0885), current_reward: 0.4695 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 15100, elapsed time: 1421 (avg 0.0877), current_reward: 0.5000 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 15120, elapsed time: 1422 (avg 0.0917), current_reward: 0.4045 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 15140, elapsed time: 1424 (avg 0.0923), current_reward: 0.5100 Action mean: [0.55] Action std: [0.49749371855331]
Episode 15160, elapsed time: 1426 (avg 0.0878), current_reward: 0.4920 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 15180, elapsed time: 1428 (avg 0.0873), current_reward: 0.5470 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 15200, elapsed time: 1429 (avg 0.0875), current_reward: 0.5135 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 15220, elapsed time: 1431 (avg 0.0931), current_reward: 0.4645 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 15240, elapsed time: 1433 (avg 0.0911), current_reward: 0.3950 Action mean: [0.33] Action std: [0.47021271782034985]
Episode 15260, elapsed time: 1435 (avg 0.0876), current_reward: 0.5310 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 15280, elapsed time: 1437 (avg 0.0875), current_reward: 0.4840 Action mean: [0.45] Action std: [0.49749371855331]
Episode 15300, elapsed time: 1438 (avg 0.0924), current_reward: 0.5575 Action mean: [0.39] Action std: [0.487749935930288]
Episode 15320, elapsed time: 1441 (avg 0.1064), current_reward: 0.4575 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 15340, elapsed time: 1443 (avg 0.0980), current_reward: 0.4785 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 15360, elapsed time: 1444 (avg 0.0926), current_reward: 0.5585 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 15380, elapsed time: 1446 (avg 0.0894), current_reward: 0.5045 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 15400, elapsed time: 1448 (avg 0.0894), current_reward: 0.4655 Action mean: [0.5] Action std: [0.5]
Episode 15420, elapsed time: 1450 (avg 0.0887), current_reward: 0.5200 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 15440, elapsed time: 1452 (avg 0.0893), current_reward: 0.4695 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 15460, elapsed time: 1453 (avg 0.0862), current_reward: 0.5995 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 15480, elapsed time: 1455 (avg 0.0877), current_reward: 0.5155 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 15500, elapsed time: 1457 (avg 0.0905), current_reward: 0.4390 Action mean: [0.43] Action std: [0.49507575177946245]
Episode 15520, elapsed time: 1459 (avg 0.0891), current_reward: 0.4655 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 15540, elapsed time: 1460 (avg 0.0888), current_reward: 0.4715 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 15560, elapsed time: 1462 (avg 0.0883), current_reward: 0.5350 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 15580, elapsed time: 1464 (avg 0.0880), current_reward: 0.5315 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 15600, elapsed time: 1466 (avg 0.0881), current_reward: 0.4980 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 15620, elapsed time: 1467 (avg 0.0883), current_reward: 0.5450 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 15640, elapsed time: 1469 (avg 0.0990), current_reward: 0.5455 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 15660, elapsed time: 1471 (avg 0.0985), current_reward: 0.5505 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 15680, elapsed time: 1473 (avg 0.0885), current_reward: 0.3895 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 15700, elapsed time: 1475 (avg 0.0881), current_reward: 0.5575 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 15720, elapsed time: 1477 (avg 0.0895), current_reward: 0.4485 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 15740, elapsed time: 1479 (avg 0.0892), current_reward: 0.4775 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 15760, elapsed time: 1480 (avg 0.0880), current_reward: 0.4490 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 15780, elapsed time: 1482 (avg 0.0880), current_reward: 0.4650 Action mean: [0.5] Action std: [0.5]
Episode 15800, elapsed time: 1484 (avg 0.0878), current_reward: 0.5025 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 15820, elapsed time: 1486 (avg 0.0877), current_reward: 0.5390 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 15840, elapsed time: 1487 (avg 0.0879), current_reward: 0.5030 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 15860, elapsed time: 1489 (avg 0.0875), current_reward: 0.4600 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 15880, elapsed time: 1491 (avg 0.0877), current_reward: 0.5060 Action mean: [0.58] Action std: [0.49355850717012273]
Episode 15900, elapsed time: 1493 (avg 0.0883), current_reward: 0.5015 Action mean: [0.45] Action std: [0.49749371855331]
Episode 15920, elapsed time: 1494 (avg 0.0885), current_reward: 0.4885 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 15940, elapsed time: 1496 (avg 0.0892), current_reward: 0.4790 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 15960, elapsed time: 1498 (avg 0.0879), current_reward: 0.4550 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 15980, elapsed time: 1500 (avg 0.0874), current_reward: 0.5350 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 16000, elapsed time: 1501 (avg 0.0912), current_reward: 0.4455 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 16020, elapsed time: 1504 (avg 0.1144), current_reward: 0.5035 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 16040, elapsed time: 1506 (avg 0.1235), current_reward: 0.4940 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 16060, elapsed time: 1509 (avg 0.1244), current_reward: 0.5170 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 16080, elapsed time: 1511 (avg 0.1143), current_reward: 0.5095 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 16100, elapsed time: 1513 (avg 0.0886), current_reward: 0.5360 Action mean: [0.5] Action std: [0.5]
Episode 16120, elapsed time: 1515 (avg 0.0876), current_reward: 0.4105 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 16140, elapsed time: 1517 (avg 0.1091), current_reward: 0.5135 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 16160, elapsed time: 1519 (avg 0.0917), current_reward: 0.5685 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 16180, elapsed time: 1521 (avg 0.1241), current_reward: 0.4880 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 16200, elapsed time: 1523 (avg 0.1121), current_reward: 0.4275 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 16220, elapsed time: 1525 (avg 0.1054), current_reward: 0.3745 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 16240, elapsed time: 1528 (avg 0.1225), current_reward: 0.6260 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 16260, elapsed time: 1530 (avg 0.1115), current_reward: 0.4470 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 16280, elapsed time: 1532 (avg 0.0864), current_reward: 0.5345 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 16300, elapsed time: 1533 (avg 0.0857), current_reward: 0.4990 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 16320, elapsed time: 1535 (avg 0.0862), current_reward: 0.4475 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 16340, elapsed time: 1537 (avg 0.0861), current_reward: 0.4515 Action mean: [0.36] Action std: [0.48]
Episode 16360, elapsed time: 1539 (avg 0.0861), current_reward: 0.4350 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 16380, elapsed time: 1540 (avg 0.0858), current_reward: 0.5610 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 16400, elapsed time: 1542 (avg 0.0913), current_reward: 0.5270 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 16420, elapsed time: 1544 (avg 0.0974), current_reward: 0.5585 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 16440, elapsed time: 1546 (avg 0.0974), current_reward: 0.5585 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 16460, elapsed time: 1548 (avg 0.0940), current_reward: 0.4630 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 16480, elapsed time: 1550 (avg 0.0946), current_reward: 0.5335 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 16500, elapsed time: 1552 (avg 0.0936), current_reward: 0.5595 Action mean: [0.45] Action std: [0.49749371855331]
Episode 16520, elapsed time: 1554 (avg 0.0950), current_reward: 0.4775 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 16540, elapsed time: 1556 (avg 0.0982), current_reward: 0.4990 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 16560, elapsed time: 1557 (avg 0.0884), current_reward: 0.5415 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 16580, elapsed time: 1559 (avg 0.0880), current_reward: 0.5310 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 16600, elapsed time: 1561 (avg 0.0883), current_reward: 0.4645 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 16620, elapsed time: 1563 (avg 0.0916), current_reward: 0.4530 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 16640, elapsed time: 1565 (avg 0.0928), current_reward: 0.5330 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 16660, elapsed time: 1567 (avg 0.0975), current_reward: 0.5075 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 16680, elapsed time: 1569 (avg 0.0990), current_reward: 0.5805 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 16700, elapsed time: 1570 (avg 0.0905), current_reward: 0.5035 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 16720, elapsed time: 1572 (avg 0.0923), current_reward: 0.5155 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 16740, elapsed time: 1574 (avg 0.0949), current_reward: 0.5630 Action mean: [0.45] Action std: [0.49749371855331]
Episode 16760, elapsed time: 1576 (avg 0.0941), current_reward: 0.5445 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 16780, elapsed time: 1578 (avg 0.0967), current_reward: 0.4445 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 16800, elapsed time: 1580 (avg 0.0945), current_reward: 0.5400 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 16820, elapsed time: 1582 (avg 0.0926), current_reward: 0.5235 Action mean: [0.53] Action std: [0.4990991885387111]
Episode 16840, elapsed time: 1583 (avg 0.0924), current_reward: 0.4985 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 16860, elapsed time: 1585 (avg 0.0870), current_reward: 0.6055 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 16880, elapsed time: 1587 (avg 0.0867), current_reward: 0.5330 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 16900, elapsed time: 1589 (avg 0.0865), current_reward: 0.5250 Action mean: [0.49] Action std: [0.4998999899979995]
Episode 16920, elapsed time: 1590 (avg 0.0906), current_reward: 0.4580 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 16940, elapsed time: 1592 (avg 0.0940), current_reward: 0.5550 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 16960, elapsed time: 1594 (avg 0.0967), current_reward: 0.4685 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 16980, elapsed time: 1596 (avg 0.0949), current_reward: 0.4820 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 17000, elapsed time: 1598 (avg 0.0930), current_reward: 0.4335 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 17020, elapsed time: 1600 (avg 0.0927), current_reward: 0.5600 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 17040, elapsed time: 1602 (avg 0.0929), current_reward: 0.4315 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 17060, elapsed time: 1604 (avg 0.0911), current_reward: 0.4850 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 17080, elapsed time: 1605 (avg 0.0906), current_reward: 0.4570 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 17100, elapsed time: 1607 (avg 0.0911), current_reward: 0.5480 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 17120, elapsed time: 1609 (avg 0.0933), current_reward: 0.5440 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 17140, elapsed time: 1611 (avg 0.0887), current_reward: 0.4775 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 17160, elapsed time: 1613 (avg 0.0897), current_reward: 0.5240 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 17180, elapsed time: 1614 (avg 0.0906), current_reward: 0.5235 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 17200, elapsed time: 1616 (avg 0.0900), current_reward: 0.4935 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 17220, elapsed time: 1618 (avg 0.0899), current_reward: 0.5710 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 17240, elapsed time: 1620 (avg 0.0897), current_reward: 0.5815 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 17260, elapsed time: 1622 (avg 0.0998), current_reward: 0.4815 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 17280, elapsed time: 1624 (avg 0.0914), current_reward: 0.4455 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 17300, elapsed time: 1625 (avg 0.0898), current_reward: 0.4500 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 17320, elapsed time: 1627 (avg 0.0898), current_reward: 0.4550 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 17340, elapsed time: 1629 (avg 0.0909), current_reward: 0.4170 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 17360, elapsed time: 1631 (avg 0.0952), current_reward: 0.4665 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 17380, elapsed time: 1633 (avg 0.0917), current_reward: 0.5150 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 17400, elapsed time: 1635 (avg 0.0899), current_reward: 0.4210 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 17420, elapsed time: 1636 (avg 0.0906), current_reward: 0.4625 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 17440, elapsed time: 1638 (avg 0.0889), current_reward: 0.5085 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 17460, elapsed time: 1640 (avg 0.0913), current_reward: 0.5000 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 17480, elapsed time: 1642 (avg 0.0904), current_reward: 0.4905 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 17500, elapsed time: 1644 (avg 0.0902), current_reward: 0.4125 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 17520, elapsed time: 1645 (avg 0.0911), current_reward: 0.3890 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 17540, elapsed time: 1647 (avg 0.0910), current_reward: 0.5745 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 17560, elapsed time: 1649 (avg 0.0904), current_reward: 0.4605 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 17580, elapsed time: 1651 (avg 0.0912), current_reward: 0.4940 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 17600, elapsed time: 1653 (avg 0.0918), current_reward: 0.5145 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 17620, elapsed time: 1655 (avg 0.0921), current_reward: 0.6670 Action mean: [0.45] Action std: [0.49749371855331]
Episode 17640, elapsed time: 1656 (avg 0.0911), current_reward: 0.4445 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 17660, elapsed time: 1658 (avg 0.0928), current_reward: 0.5300 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 17680, elapsed time: 1660 (avg 0.0917), current_reward: 0.5375 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 17700, elapsed time: 1662 (avg 0.0903), current_reward: 0.5300 Action mean: [0.58] Action std: [0.49355850717012273]
Episode 17720, elapsed time: 1664 (avg 0.0907), current_reward: 0.4330 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 17740, elapsed time: 1666 (avg 0.0889), current_reward: 0.5110 Action mean: [0.5] Action std: [0.5]
Episode 17760, elapsed time: 1667 (avg 0.0880), current_reward: 0.4865 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 17780, elapsed time: 1669 (avg 0.0900), current_reward: 0.5210 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 17800, elapsed time: 1671 (avg 0.0898), current_reward: 0.4480 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 17820, elapsed time: 1673 (avg 0.0906), current_reward: 0.5730 Action mean: [0.56] Action std: [0.4963869458396343]
Episode 17840, elapsed time: 1674 (avg 0.0886), current_reward: 0.4970 Action mean: [0.5] Action std: [0.5]
Episode 17860, elapsed time: 1676 (avg 0.0884), current_reward: 0.4880 Action mean: [0.5] Action std: [0.5]
Episode 17880, elapsed time: 1678 (avg 0.0910), current_reward: 0.4530 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 17900, elapsed time: 1680 (avg 0.1032), current_reward: 0.4920 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 17920, elapsed time: 1682 (avg 0.0915), current_reward: 0.4140 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 17940, elapsed time: 1684 (avg 0.0929), current_reward: 0.5050 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 17960, elapsed time: 1686 (avg 0.0922), current_reward: 0.5715 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 17980, elapsed time: 1687 (avg 0.0908), current_reward: 0.5945 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 18000, elapsed time: 1689 (avg 0.0878), current_reward: 0.5005 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 18020, elapsed time: 1691 (avg 0.0945), current_reward: 0.4365 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 18040, elapsed time: 1693 (avg 0.0930), current_reward: 0.4950 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 18060, elapsed time: 1695 (avg 0.0925), current_reward: 0.5475 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 18080, elapsed time: 1697 (avg 0.0938), current_reward: 0.5410 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 18100, elapsed time: 1698 (avg 0.0882), current_reward: 0.4465 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 18120, elapsed time: 1700 (avg 0.0883), current_reward: 0.5530 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18140, elapsed time: 1702 (avg 0.0935), current_reward: 0.4940 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18160, elapsed time: 1704 (avg 0.0943), current_reward: 0.4640 Action mean: [0.45] Action std: [0.49749371855331]
Episode 18180, elapsed time: 1706 (avg 0.0971), current_reward: 0.5170 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 18200, elapsed time: 1708 (avg 0.0926), current_reward: 0.5205 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 18220, elapsed time: 1710 (avg 0.0940), current_reward: 0.4715 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 18240, elapsed time: 1712 (avg 0.0932), current_reward: 0.4710 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 18260, elapsed time: 1713 (avg 0.0939), current_reward: 0.5250 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 18280, elapsed time: 1715 (avg 0.0939), current_reward: 0.4995 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 18300, elapsed time: 1717 (avg 0.0910), current_reward: 0.5160 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 18320, elapsed time: 1719 (avg 0.0919), current_reward: 0.5190 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18340, elapsed time: 1721 (avg 0.1042), current_reward: 0.5135 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18360, elapsed time: 1723 (avg 0.0953), current_reward: 0.5630 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18380, elapsed time: 1725 (avg 0.0971), current_reward: 0.4890 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 18400, elapsed time: 1727 (avg 0.0944), current_reward: 0.5010 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 18420, elapsed time: 1729 (avg 0.0948), current_reward: 0.5910 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 18440, elapsed time: 1731 (avg 0.0944), current_reward: 0.4325 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 18460, elapsed time: 1733 (avg 0.1033), current_reward: 0.4565 Action mean: [0.36] Action std: [0.48000000000000004]
Episode 18480, elapsed time: 1735 (avg 0.0959), current_reward: 0.4825 Action mean: [0.51] Action std: [0.4998999899979995]
Episode 18500, elapsed time: 1736 (avg 0.0965), current_reward: 0.5470 Action mean: [0.52] Action std: [0.4995998398718718]
Episode 18520, elapsed time: 1738 (avg 0.0937), current_reward: 0.5435 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 18540, elapsed time: 1740 (avg 0.0913), current_reward: 0.4680 Action mean: [0.46] Action std: [0.4983974317750845]
Episode 18560, elapsed time: 1742 (avg 0.0863), current_reward: 0.4465 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 18580, elapsed time: 1744 (avg 0.0864), current_reward: 0.4495 Action mean: [0.36] Action std: [0.48]
Episode 18600, elapsed time: 1745 (avg 0.0860), current_reward: 0.4260 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 18620, elapsed time: 1747 (avg 0.0865), current_reward: 0.5150 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 18640, elapsed time: 1749 (avg 0.0866), current_reward: 0.4495 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 18660, elapsed time: 1751 (avg 0.0863), current_reward: 0.5650 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 18680, elapsed time: 1752 (avg 0.0866), current_reward: 0.5055 Action mean: [0.45] Action std: [0.49749371855331]
Episode 18700, elapsed time: 1754 (avg 0.0863), current_reward: 0.4535 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 18720, elapsed time: 1756 (avg 0.0855), current_reward: 0.4655 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 18740, elapsed time: 1757 (avg 0.0864), current_reward: 0.5645 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 18760, elapsed time: 1759 (avg 0.0866), current_reward: 0.4825 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 18780, elapsed time: 1761 (avg 0.0862), current_reward: 0.5570 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 18800, elapsed time: 1763 (avg 0.0861), current_reward: 0.5265 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 18820, elapsed time: 1764 (avg 0.0864), current_reward: 0.5075 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 18840, elapsed time: 1766 (avg 0.0858), current_reward: 0.5110 Action mean: [0.37] Action std: [0.4828043081829324]
Episode 18860, elapsed time: 1768 (avg 0.0858), current_reward: 0.5270 Action mean: [0.35] Action std: [0.4769696007084728]
Episode 18880, elapsed time: 1769 (avg 0.0865), current_reward: 0.4730 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 18900, elapsed time: 1771 (avg 0.0855), current_reward: 0.4420 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 18920, elapsed time: 1773 (avg 0.0857), current_reward: 0.4740 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 18940, elapsed time: 1775 (avg 0.0859), current_reward: 0.4870 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 18960, elapsed time: 1776 (avg 0.0856), current_reward: 0.5105 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 18980, elapsed time: 1778 (avg 0.0866), current_reward: 0.5755 Action mean: [0.45] Action std: [0.49749371855331]
Episode 19000, elapsed time: 1780 (avg 0.0861), current_reward: 0.4030 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 19020, elapsed time: 1782 (avg 0.0863), current_reward: 0.5310 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 19040, elapsed time: 1783 (avg 0.0861), current_reward: 0.4900 Action mean: [0.57] Action std: [0.4950757517794625]
Episode 19060, elapsed time: 1785 (avg 0.0864), current_reward: 0.5115 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 19080, elapsed time: 1787 (avg 0.0859), current_reward: 0.4785 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 19100, elapsed time: 1788 (avg 0.0858), current_reward: 0.4415 Action mean: [0.53] Action std: [0.49909918853871116]
Episode 19120, elapsed time: 1790 (avg 0.0859), current_reward: 0.5560 Action mean: [0.45] Action std: [0.49749371855331]
Episode 19140, elapsed time: 1792 (avg 0.0854), current_reward: 0.5560 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 19160, elapsed time: 1794 (avg 0.0877), current_reward: 0.4065 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 19180, elapsed time: 1795 (avg 0.0873), current_reward: 0.5065 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 19200, elapsed time: 1797 (avg 0.0876), current_reward: 0.4605 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 19220, elapsed time: 1799 (avg 0.0857), current_reward: 0.4575 Action mean: [0.47] Action std: [0.49909918853871116]
Episode 19240, elapsed time: 1801 (avg 0.0863), current_reward: 0.5910 Action mean: [0.55] Action std: [0.49749371855331]
Episode 19260, elapsed time: 1802 (avg 0.0914), current_reward: 0.5690 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 19280, elapsed time: 1804 (avg 0.0941), current_reward: 0.4800 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 19300, elapsed time: 1806 (avg 0.0975), current_reward: 0.4400 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 19320, elapsed time: 1808 (avg 0.0953), current_reward: 0.5110 Action mean: [0.49] Action std: [0.49989998999799945]
Episode 19340, elapsed time: 1810 (avg 0.1075), current_reward: 0.4735 Action mean: [0.37] Action std: [0.48280430818293246]
Episode 19360, elapsed time: 1812 (avg 0.0959), current_reward: 0.5285 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 19380, elapsed time: 1814 (avg 0.0927), current_reward: 0.4455 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 19400, elapsed time: 1816 (avg 0.1046), current_reward: 0.5890 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 19420, elapsed time: 1818 (avg 0.0904), current_reward: 0.5365 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 19440, elapsed time: 1820 (avg 0.0932), current_reward: 0.5975 Action mean: [0.41] Action std: [0.49183330509431744]
Episode 19460, elapsed time: 1822 (avg 0.0894), current_reward: 0.5080 Action mean: [0.48] Action std: [0.49959983987187184]
Episode 19480, elapsed time: 1823 (avg 0.0888), current_reward: 0.5315 Action mean: [0.45] Action std: [0.4974937185533101]
Episode 19500, elapsed time: 1825 (avg 0.0887), current_reward: 0.5575 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 19520, elapsed time: 1827 (avg 0.0878), current_reward: 0.5140 Action mean: [0.52] Action std: [0.49959983987187184]
Episode 19540, elapsed time: 1829 (avg 0.0880), current_reward: 0.4445 Action mean: [0.43] Action std: [0.4950757517794625]
Episode 19560, elapsed time: 1830 (avg 0.0877), current_reward: 0.4820 Action mean: [0.38] Action std: [0.48538644398046393]
Episode 19580, elapsed time: 1832 (avg 0.0883), current_reward: 0.5535 Action mean: [0.4] Action std: [0.48989794855663565]
Episode 19600, elapsed time: 1834 (avg 0.0887), current_reward: 0.4630 Action mean: [0.44] Action std: [0.4963869458396343]
Episode 19620, elapsed time: 1836 (avg 0.0889), current_reward: 0.4465 Action mean: [0.39] Action std: [0.4877499359302879]
Episode 19640, elapsed time: 1837 (avg 0.0884), current_reward: 0.3875 Action mean: [0.41] Action std: [0.4918333050943174]
Episode 19660, elapsed time: 1839 (avg 0.0877), current_reward: 0.5065 Action mean: [0.45] Action std: [0.49749371855331]
Episode 19680, elapsed time: 1841 (avg 0.0875), current_reward: 0.4890 Action mean: [0.44] Action std: [0.49638694583963433]
Episode 19700, elapsed time: 1843 (avg 0.0877), current_reward: 0.5090 Action mean: [0.48] Action std: [0.4995998398718718]
Episode 19720, elapsed time: 1844 (avg 0.0876), current_reward: 0.4070 Action mean: [0.5] Action std: [0.5]
Episode 19740, elapsed time: 1846 (avg 0.0877), current_reward: 0.3700 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 19760, elapsed time: 1848 (avg 0.0876), current_reward: 0.5110 Action mean: [0.54] Action std: [0.49839743177508444]
Episode 19780, elapsed time: 1850 (avg 0.0879), current_reward: 0.4860 Action mean: [0.46] Action std: [0.49839743177508444]
Episode 19800, elapsed time: 1851 (avg 0.0876), current_reward: 0.4550 Action mean: [0.51] Action std: [0.49989998999799945]
Episode 19820, elapsed time: 1853 (avg 0.0877), current_reward: 0.4520 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 19840, elapsed time: 1855 (avg 0.0878), current_reward: 0.4970 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 19860, elapsed time: 1857 (avg 0.0913), current_reward: 0.5305 Action mean: [0.4] Action std: [0.4898979485566356]
Episode 19880, elapsed time: 1859 (avg 0.0921), current_reward: 0.5005 Action mean: [0.41] Action std: [0.4918333050943175]
Episode 19900, elapsed time: 1861 (avg 0.0946), current_reward: 0.5225 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 19920, elapsed time: 1862 (avg 0.0901), current_reward: 0.4475 Action mean: [0.45] Action std: [0.49749371855331004]
Episode 19940, elapsed time: 1864 (avg 0.0890), current_reward: 0.5815 Action mean: [0.42] Action std: [0.49355850717012273]
Episode 19960, elapsed time: 1866 (avg 0.0964), current_reward: 0.4950 Action mean: [0.47] Action std: [0.4990991885387111]
Episode 19980, elapsed time: 1868 (avg 0.0926), current_reward: 0.4795 Action mean: [0.41] Action std: [0.49183330509431744]